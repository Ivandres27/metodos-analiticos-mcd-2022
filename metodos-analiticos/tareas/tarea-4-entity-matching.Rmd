---
title: "Tarea 3. Joins por similitud y Entity matching"
output: html_notebook
---


En este ejemplo veremos como usar LSH 
para encontrar registros
que se refieren al mismo elemento pero están en distintas tablas, 
y pueden diferir en cómo están registrados (entity matching). Este también
es un ejemplo

## Datos

Los [datos](https://dbs.uni-leipzig.de/de/research/projects/object_matching/fever/benchmark_datasets_for_entity_resolution) para este ejempo particular trata con dos fuentes bibliográficas (DBLP, ACM)
de artículos y conferencias de cómputo. La carpeta del repositorio
es datos/similitud/entity-matching. **El objetivo es parear las dos fuentes para
identificar artículos que se presenteron en las dos referencias.**


```{r, warning=FALSE, message=FALSE}
library(tidyverse)
acm <- read_csv('../datos/entity_matching/ACM.csv')
dbl <- read_csv('../datos/entity_matching/DBLP2.csv')
```

```{r}
head(acm)
head(dbl)
nrow(acm)
nrow(dbl)
```

**Pregunta 1**: ¿si intentas una aproximación por fuerza bruta, cuántas comparaciones
tendrías que hacer? Si cada tabla contuviera unos 2 millones de documentos, ¿qué tan 
factible sería hacer todas las posibles comparaciones?

<<<<<<< HEAD
**Con 2 millones de de documentos se tendrian que hacer 4 billones (2 millones^2) de comparaciones**
=======
```{r}
nrow(acm) * nrow(dbl) 
2e6 * 2e6 / 2
```

>>>>>>> 1b3c8c66919face7c9e876b62f0433c7e43c7a87

## Tejas y hashing

Primero hacemos una limpieza básica (puedes reconsiderar este proceso
más adelante cuando veamos los resultados)_

```{r}
acm_1 <- acm |> select(id, title, authors) |> 
  mutate(texto = paste(title, authors, sep = "    ")) |> 
  mutate(id = as.character(id)) |> 
  mutate(texto = str_to_lower(texto)) |> 
  mutate(texto = str_remove_all(texto, pattern = "[^a-z -]"))
dbl_1 <- dbl |> select(id, title, authors) |> 
  mutate(texto = paste(title, authors, sep = "    ")) |> 
  mutate(texto = str_to_lower(texto)) |> 
  mutate(texto = str_remove_all(texto, pattern = "[^a-z -]"))
```

<<<<<<< HEAD
**Pregunta 2**: ¿por qué definimos el texto incluyendo algún espacio en blanco entre título y autor?

**Para que a la hora de examinar a través de tejas se pueda hacer una distincion entre el titulo y los nombres de los autores**

¿Qué otra estrategia se te ocurre para convertir en tejas?
**Otra posible estrategia es hacer una columna de tejas por texto y otra por autores y evaluar candidatos por similitud en texto y autores**

=======
**Pregunta 2**: ¿por qué definimos el texto incluyendo algún espacio en blanco entre título y autor? ¿Qué otra estrategia se te ocurre para convertir en tejas?

Vamos a usar tejas de tamaño 5, y así las tejas de título y autor están separadas.
>>>>>>> 1b3c8c66919face7c9e876b62f0433c7e43c7a87

**Pregunta 3**: cuántas comparaciones tendrías que hacer si calcularas
la similitud entre todos los posibles pares?
**Se tendrian que hacer 2294*2616=6001104 comparaciones**


```{r}
# función de las notas
calcular_tejas <- function(x, k = 4, lowercase = FALSE){
  tokenizers::tokenize_character_shingles(x, n = k, lowercase = lowercase,
    simplify = TRUE, strip_non_alpha = FALSE)
}
generar_hash <- function(){
  r <- as.integer(stats::runif(1, 1, 2147483647))
  funcion_hash <- function(tejas){
        digest::digest2int(tejas, seed = r) 
  }
  funcion_hash
}
```

En este caso escogemos 2 hashes,
tejas de tamaño 5, y usamos sólo título y autor.


```{r}
# el siguiente devuelve un objeto con los minhashes calculados
acm_tejas <- acm_1 |> 
  mutate(tejas = map(texto, ~ calcular_tejas(.x, k = 5)))
dbl_tejas <- dbl_1 |> 
  mutate(tejas = map(texto, ~ calcular_tejas(.x, k = 5)))
```

Por ejemplo, para el primer documento tenemos el contenido y los minhashes calculados:

```{r}
acm_tejas$texto[[1]]
acm_tejas$tejas[[1]]
```

Ahora calculamos minhashes

```{r}
set.seed(88345)
# crear hashes
hashes <- map(1:3, ~ generar_hash())

construir_firmas <- function(hashes, tejas){
  tibble(hash_num = 1:length(hashes), 
         firma = map_int(hashes, \(h) min(h(tejas)))
  )
}

acm_firmas <- acm_tejas |> 
  mutate(firma = map(tejas, ~ construir_firmas(hashes, .x))) |> 
  select(id, firma) |> 
  unnest(firma) |> 
  mutate(cubeta = paste(hash_num, firma, sep = "-")) |> 
  select(id, cubeta)
dbl_firmas <- dbl_tejas |> 
  mutate(firma = map(tejas, ~ construir_firmas(hashes, .x))) |> 
  select(id, firma) |> 
  unnest(firma) |> 
  mutate(cubeta = paste(hash_num, firma, sep = "-")) |> 
  select(id, cubeta)
```

Ahora hacemos una unión por cubetas para obtener nuestros pares candidatos:

```{r}
candidatos_tbl <- inner_join(acm_firmas |> rename(idACM = id), 
                          dbl_firmas |> rename(idDBL = id))
candidatos_tbl
```



## Examinar pares candidatos

Ahora calculamos similitud exacta para candidatos

```{r}
sim_jaccard <- \(a, b)  length(intersect(a, b)) / length(union(a, b))
candidatos_score_tbl <- candidatos_tbl |> 
  left_join(acm_tejas |>
              select(idACM = id, tejas_acm = tejas)) |> 
  left_join(dbl_tejas |> 
              select(idDBL = id, tejas_dbl = tejas)) |> 
  mutate(score = map2_dbl(tejas_acm, tejas_dbl, ~ sim_jaccard(.x, .y))) |> 
  select(-tejas_acm, -tejas_dbl, -cubeta)
candidatos_score_tbl <- candidatos_score_tbl |> 
  unique()
candidatos_score_tbl
```



**Pregunta 4**: explica cómo se calcula la columna *score* en la tabla de candidatos,
y da unos ejemplos.

<<<<<<< HEAD
**El score se calcula con la formula de similitud de jaccard dentro se los pares que fueron agrupados en las cubetas como candidatos**
=======
Similitud de jaccard entre las tejas de los candidatos.

```{r}
candidatos_score_tbl |> summarise(media_score = mean(score))
candidatos_score_tbl |> ggplot(aes(sample = score)) + geom_qq(distribution = stats::qunif)
```

>>>>>>> 1b3c8c66919face7c9e876b62f0433c7e43c7a87


**Pregunta 5**: ¿Cuántas comparaciones tuviste qué hacer (cálculos de similitud)? Compara con el total
de comparaciones que es posible hacer entre estas dos tablas.

<<<<<<< HEAD
**El score de los candidatos se realizo a 145757 en comparaión de las 6001104 de posibles comparaciones entre ambas tablas**
=======
```{r}
nrow(candidatos_score_tbl)
```

>>>>>>> 1b3c8c66919face7c9e876b62f0433c7e43c7a87

**Pregunta 6**: 
¿Cuántos pares candidatos obtuviste?
**Se analizarón 145757 pares candidatos**

Examina algunos elementos con similitud uno o cercana a uno. ¿Se refieren al
mismo artículo en las dos fuentes? 

```{r}
<<<<<<< HEAD
candidatos_ordenados<-arrange(candidatos_score_tbl,score)
head(candidatos_ordenados)
=======
candidatos_score_tbl |> arrange(desc(score))
```


```{r}
filter(dbl_1, id == "journals/sigmod/BuchnerM98") |> pull(texto)
filter(acm_1, id == 306124) |> pull(texto)
>>>>>>> 1b3c8c66919face7c9e876b62f0433c7e43c7a87
```


## Examinar resultados

```{r}
acm_filt<- filter(acm_1,id %in% C$idACM)
dbl_filt<- filter(dbl_1,id %in% C$idDBL)
comparaciones<-tibble(acm_title=acm_filt$title,dbl_title=dbl_filt$title,acm_authors=acm_filt$authors,dbl_authors=dbl_filt$authors)
```



**Pregunta 8**: Ahora considera los elementos con similitud más baja que capturaste. Examina varios casos y concluye si hay pares que no se refieren al mismo artículo, y por qué.

**Comparando los casos con score mas bajo solo uno par comparten el mismo titulo**

**Pregunta 9**: propón un punto de corte de similitud para la tabla de arriba, según tus
observaciones de la pregunta anterior.


```{r}
# código filtrando con score > tu_numero, y examinando los elementos
# de similitud más baja
candidatos_filt <- filter(candidatos_score_tbl, score > 0.1)
tail(candidatos_filt)
nrow(candidatos_filt)
```

**Pregunta 10**: ¿cuántos pares candidatos obtuviste al final?

<<<<<<< HEAD
**Con una tolerancia de score > 0.1 hay 9830 pares candidatos**
=======
```{r}
nrow(candidatos_filt)
```
>>>>>>> 1b3c8c66919face7c9e876b62f0433c7e43c7a87


## Evaluación de resultados

 Evalúa tus resultados con las respuestas
correctas, que están en la carpeta de los datos.


```{r}
mapping <- read_csv("../datos/entity_matching/DBLP-ACM_perfectMapping.csv") |> 
  rename(idDBL = idDBLP)
```


Podemos calcular el número de pares verdaderos que son candidatos (recuperados), el número de pares
candidatos que son candidatos pero no son pares verdaderos, por ejemplo:

```{r}
mapping <- mapping |> mutate(idACM = as.character(idACM)) 
ambos <- inner_join(candidatos_filt, mapping)
nrow(candidatos_filt)
nrow(ambos)
```

*Pregunta 11*: ¿Hubiera funcionado igualmente bien hacer un join usando 
autores o título en lugar de este join por similitud?

**No hubiera sido igual dado que parte de la similitud se da por ambos factores que se incluyen en las tejas de cada texto**

*Pregunta 12 *: Evalúa precisión y recall de tu método. Para distintas aplicaciones que te
puedas imaginar, ¿qué tan buenos son estos resultados? ¿Qué consideras
mejor en este punto, tener precisión o recall alto? 



```{r}
<<<<<<< HEAD
falsos_negativos<-nrow(anti_join(mapping, candidatos_filt)) 
falsos_positivos<-nrow(anti_join(candidatos_filt, mapping))
precision <- 2224/(2224+falsos_positivos)
precision
recall <- 2224/(2224+falsos_negativos)
=======
precision <- nrow(ambos) / nrow(candidatos_filt)
precision
recall <- nrow(ambos) / nrow(mapping)
>>>>>>> 1b3c8c66919face7c9e876b62f0433c7e43c7a87
recall
```


## Análisis de errores

Considera algunos casos que fallamos en recuperar como candidatos. Examina algunos
de los siguientes pares:

```{r}
anti_join(mapping, candidatos_filt) 
```

También puedes examinar falsos positivos:

```{r}
anti_join(candidatos_filt, mapping) 
```


**Pregunta 11**: Considerando estos errores, ¿qué se te ocurre para mejorar el método?

- Corregir encoding DBLP
- Hacer análisis posterior checando solo titulo (darle menos peso a los autores),
solo con los candidatos del primer procesamiento.
